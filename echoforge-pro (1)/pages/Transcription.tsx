import React, { useState, useRef, useEffect } from 'react';
import { Mic, Upload, FileAudio, CheckCircle2, Clock, AlertTriangle, FileText, Download, ShieldCheck, Users, Globe } from 'lucide-react';

const Transcription: React.FC = () => {
  const [mode, setMode] = useState<'live' | 'file'>('live');
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [confidence, setConfidence] = useState(0);
  const [file, setFile] = useState<File | null>(null);
  const [processingProgress, setProcessingProgress] = useState(0);
  const [isProcessing, setIsProcessing] = useState(false);
  
  // Model Configuration
  const [language, setLanguage] = useState('en-US');
  const [speakerCount, setSpeakerCount] = useState<number>(2);

  // Web Speech API Refs
  const recognitionRef = useRef<any>(null);

  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
        recognitionRef.current = new SpeechRecognition();
        recognitionRef.current.continuous = true;
        recognitionRef.current.interimResults = true;
        recognitionRef.current.lang = language;

        recognitionRef.current.onresult = (event: any) => {
            let interimTranscript = '';
            let finalTranscript = '';

            for (let i = event.resultIndex; i < event.results.length; ++i) {
                if (event.results[i].isFinal) {
                    finalTranscript += event.results[i][0].transcript;
                } else {
                    interimTranscript += event.results[i][0].transcript;
                }
            }
            
            setConfidence(event.results[0][0].confidence * 100);
            
            if (finalTranscript) {
                setTranscript(prev => prev + ' ' + finalTranscript);
            }
        };

        recognitionRef.current.onerror = (event: any) => {
            console.error("Speech Error", event.error);
            setIsRecording(false);
        };
    }
  }, []);

  // Update language dynamically
  useEffect(() => {
      if (recognitionRef.current && language !== 'auto') {
          recognitionRef.current.lang = language;
      }
  }, [language]);

  const toggleRecording = () => {
    if (isRecording) {
        recognitionRef.current?.stop();
        setIsRecording(false);
    } else {
        setTranscript('');
        recognitionRef.current?.start();
        setIsRecording(true);
    }
  };

  const handleFileUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files[0]) {
        setFile(e.target.files[0]);
        setTranscript('');
        setProcessingProgress(0);
    }
  };

  const startBatchTranscription = () => {
    if (!file) return;
    setIsProcessing(true);
    setTranscript('');
    
    // Simulate SenseVoice / Whisper Processing
    let progress = 0;
    const interval = setInterval(() => {
        progress += Math.random() * 15;
        if (progress >= 100) {
            clearInterval(interval);
            setProcessingProgress(100);
            setIsProcessing(false);
            
            // Simulated diarized output based on config
            const speakers = Array.from({length: speakerCount}, (_, i) => `SPEAKER_${String.fromCharCode(65+i)}`);
            const langPrefix = language === 'ja-JP' ? '[JP] ' : language === 'es-ES' ? '[ES] ' : '';
            
            setTranscript(`[00:00:01] ${speakers[0]}: ${langPrefix}Welcome to the EchoForge Pro architecture demonstration.
[00:00:05] ${speakers[1 % speakerCount]}: ${langPrefix}This text was generated by the local SenseVoice model running on your GPU.
[00:00:12] ${speakers[0]}: ${langPrefix}As you can see, the diarization and timestamps are perfectly aligned for ${speakerCount} speakers.
[00:00:18] ${speakers[1 % speakerCount]}: ${langPrefix}And unlike cloud providers, this data never left your machine.`);
        } else {
            setProcessingProgress(Math.min(progress, 99));
        }
    }, 500);
  };

  return (
    <div className="h-full p-8 overflow-y-auto">
      <header className="mb-8 flex justify-between items-end">
        <div>
            <h2 className="text-3xl font-bold text-white mb-2">Neural Transcription (STT)</h2>
            <p className="text-gray-400">
                Outperform ElevenLabs & Otter.ai with <span className="text-forge-accent">SenseVoice & Whisper Large v3</span>.
            </p>
        </div>
        <div className="flex gap-2">
            <button 
                onClick={() => setMode('live')}
                className={`px-4 py-2 rounded-lg font-medium transition-all ${mode === 'live' ? 'bg-forge-accent text-forge-900' : 'bg-forge-800 text-gray-400 hover:text-white'}`}
            >
                Live Dictation
            </button>
            <button 
                onClick={() => setMode('file')}
                className={`px-4 py-2 rounded-lg font-medium transition-all ${mode === 'file' ? 'bg-forge-accent text-forge-900' : 'bg-forge-800 text-gray-400 hover:text-white'}`}
            >
                Batch File
            </button>
        </div>
      </header>

      <div className="grid grid-cols-1 lg:grid-cols-3 gap-8 h-[calc(100%-120px)]">
        {/* Input Column */}
        <div className="lg:col-span-1 space-y-6">
            <div className="bg-forge-800 p-6 rounded-xl border border-forge-700">
                <h3 className="text-lg font-bold text-white mb-4">Input Source</h3>
                
                {mode === 'live' ? (
                    <div className="flex flex-col items-center justify-center py-8">
                        <button 
                            onClick={toggleRecording}
                            className={`w-24 h-24 rounded-full flex items-center justify-center transition-all ${
                                isRecording 
                                ? 'bg-red-500 hover:bg-red-600 shadow-[0_0_30px_rgba(255,0,0,0.4)] animate-pulse' 
                                : 'bg-forge-700 hover:bg-forge-600 border-2 border-forge-500 text-white'
                            }`}
                        >
                            <Mic size={40} className={isRecording ? 'text-white' : 'text-gray-400'} />
                        </button>
                        <p className="mt-4 text-sm font-mono text-gray-400">
                            {isRecording ? 'Listening...' : 'Tap to Record'}
                        </p>
                        {isRecording && (
                             <div className="mt-4 flex gap-1 h-8 items-end">
                                {[1,2,3,4,5].map(i => (
                                    <div key={i} className="w-1.5 bg-forge-accent animate-pulse" style={{height: `${Math.random() * 100}%`}}></div>
                                ))}
                             </div>
                        )}
                    </div>
                ) : (
                    <div className="space-y-4">
                        <div className="border-2 border-dashed border-forge-600 rounded-lg p-8 flex flex-col items-center justify-center text-center cursor-pointer hover:border-forge-accent hover:bg-forge-900/50 transition-all relative">
                            <input type="file" onChange={handleFileUpload} accept="audio/*,video/*" className="absolute inset-0 opacity-0 cursor-pointer" />
                            {file ? (
                                <>
                                    <FileAudio size={40} className="text-forge-success mb-2" />
                                    <p className="text-white font-medium truncate w-full">{file.name}</p>
                                    <p className="text-xs text-gray-500">{(file.size / 1024 / 1024).toFixed(2)} MB</p>
                                </>
                            ) : (
                                <>
                                    <Upload size={40} className="text-gray-500 mb-2" />
                                    <p className="text-gray-300">Drop Audio/Video</p>
                                    <p className="text-xs text-gray-500">Supports WAV, MP3, MP4</p>
                                </>
                            )}
                        </div>

                        {file && (
                             <button 
                                onClick={startBatchTranscription}
                                disabled={isProcessing}
                                className="w-full bg-forge-accent text-forge-900 font-bold py-3 rounded-lg hover:bg-cyan-400 disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
                            >
                                {isProcessing ? 'Processing (SenseVoice)...' : 'Start Transcription'}
                            </button>
                        )}
                    </div>
                )}
            </div>

            <div className="bg-forge-800 p-6 rounded-xl border border-forge-700">
                <h3 className="text-lg font-bold text-white mb-4">Model Config</h3>
                <div className="space-y-5">
                    {/* Language Selector */}
                    <div>
                        <label className="text-sm text-gray-400 mb-2 flex items-center gap-2">
                            <Globe size={14} /> Target Language
                        </label>
                        <select 
                            value={language}
                            onChange={(e) => setLanguage(e.target.value)}
                            className="w-full bg-forge-900 border border-forge-600 rounded-lg p-2.5 text-white text-sm outline-none focus:border-forge-accent focus:ring-1 focus:ring-forge-accent transition-all appearance-none cursor-pointer hover:bg-forge-800"
                        >
                            <option value="auto">Auto-Detect (SenseVoice)</option>
                            <option value="en-US">English (US)</option>
                            <option value="en-GB">English (UK)</option>
                            <option value="es-ES">Spanish (Español)</option>
                            <option value="fr-FR">French (Français)</option>
                            <option value="de-DE">German (Deutsch)</option>
                            <option value="ja-JP">Japanese (日本語)</option>
                            <option value="zh-CN">Chinese (Mandarin)</option>
                        </select>
                    </div>

                    {/* Speaker Count Slider */}
                    <div>
                        <div className="flex justify-between mb-2">
                             <label className="text-sm text-gray-400 flex items-center gap-2">
                                <Users size={14} /> Diarization Hint
                             </label>
                             <span className="text-xs font-bold text-forge-accent">{speakerCount} Speakers</span>
                        </div>
                        <input 
                            type="range"
                            min="1"
                            max="8"
                            step="1"
                            value={speakerCount}
                            onChange={(e) => setSpeakerCount(parseInt(e.target.value))}
                            className="w-full h-1.5 bg-forge-900 rounded-lg appearance-none cursor-pointer accent-forge-accent hover:accent-cyan-300"
                        />
                        <p className="text-[10px] text-gray-500 mt-2">
                            Adjust count to help the model separate voices in batch mode.
                        </p>
                    </div>

                    <div className="h-px bg-forge-700 my-1"></div>

                    {/* Status Indicators */}
                    <div className="flex justify-between items-center">
                        <span className="text-sm text-gray-400">Engine</span>
                        <span className="text-xs font-mono bg-forge-900 px-2 py-1 rounded text-forge-accent">
                            {mode === 'live' ? 'WebSpeech' : 'SenseVoice'}
                        </span>
                    </div>
                    <div className="flex justify-between items-center">
                        <span className="text-sm text-gray-400">Mode</span>
                         <span className={`text-xs font-mono px-2 py-1 rounded border ${speakerCount > 1 ? 'bg-green-900/30 text-green-400 border-green-900' : 'bg-gray-800 text-gray-500 border-gray-700'}`}>
                            {speakerCount > 1 ? 'Multi-Speaker' : 'Mono'}
                        </span>
                    </div>
                     <div className="flex justify-between items-center">
                        <span className="text-sm text-gray-400">Privacy</span>
                        <div className="flex items-center gap-1 text-xs font-mono bg-blue-900/30 text-blue-400 px-2 py-1 rounded border border-blue-900">
                            <ShieldCheck size={12} /> Local
                        </div>
                    </div>
                </div>
            </div>
            
            {mode === 'live' && isRecording && (
                <div className="bg-forge-800 p-6 rounded-xl border border-forge-700">
                     <h3 className="text-sm font-bold text-white mb-2">Confidence Score</h3>
                     <div className="flex items-end gap-2">
                        <span className="text-4xl font-bold text-forge-accent">{confidence.toFixed(0)}%</span>
                        <span className="text-xs text-gray-500 mb-1.5">Real-time accuracy</span>
                     </div>
                </div>
            )}
        </div>

        {/* Output Column */}
        <div className="lg:col-span-2 flex flex-col gap-6">
            <div className="bg-forge-900 border border-forge-700 rounded-xl flex-1 flex flex-col overflow-hidden relative">
                <div className="flex justify-between items-center p-4 border-b border-forge-700 bg-forge-800">
                    <div className="flex items-center gap-2">
                        <FileText size={18} className="text-gray-400" />
                        <span className="font-medium text-gray-200">Transcription Output</span>
                    </div>
                    <button className="text-xs flex items-center gap-1 hover:text-white text-gray-400 transition-colors">
                        <Download size={14} /> Export TXT
                    </button>
                </div>
                
                <div className="flex-1 p-6 overflow-y-auto font-mono text-sm leading-relaxed text-gray-300 space-y-4">
                    {isProcessing ? (
                        <div className="flex flex-col items-center justify-center h-full">
                            <div className="w-full max-w-md space-y-2">
                                <div className="flex justify-between text-xs text-gray-400">
                                    <span>Inferencing...</span>
                                    <span>{processingProgress.toFixed(0)}%</span>
                                </div>
                                <div className="w-full bg-forge-800 h-2 rounded-full overflow-hidden">
                                    <div className="bg-forge-accent h-full transition-all duration-300" style={{width: `${processingProgress}%`}}></div>
                                </div>
                                <p className="text-center text-xs text-gray-500 mt-2">Running SenseVoice Large on GPU (cuda:0)</p>
                            </div>
                        </div>
                    ) : transcript ? (
                        <div className="whitespace-pre-wrap">{transcript}</div>
                    ) : (
                        <div className="h-full flex flex-col items-center justify-center text-gray-600 opacity-50">
                            <FileText size={48} className="mb-4" />
                            <p>No transcription yet.</p>
                        </div>
                    )}
                </div>
            </div>
        </div>
      </div>
    </div>
  );
};

export default Transcription;